# Chapter 5.7: Common Pitfalls and Errors

## What This Chapter is About

This chapter explains **common problems you'll encounter with Terraform** and how to solve them. These issues often stem from the resource graph concepts we learned in chapters 5.1-5.2, but with practical solutions you can apply immediately.

## Key Concept: Learning from Common Mistakes

Think of these pitfalls like:
- **Driving hazards**: Common road problems every driver learns to navigate
- **Cooking mistakes**: Issues every chef encounters and learns to avoid
- **Sports fouls**: Common rule violations that players learn to prevent

## Circular Dependencies

### What Are Circular Dependencies?

A circular dependency happens when resources depend on each other in a loop:

```bash
# The Problem: A → B → C → A (forms a circle)
resource "null_resource" "alpha" {
  triggers = {
    rebuild = null_resource.charlie.id  # alpha depends on charlie
  }
}

resource "null_resource" "bravo" {
  triggers = {
    rebuild = null_resource.alpha.id    # bravo depends on alpha
  }
}

resource "null_resource" "charlie" {
  triggers = {
    rebuild = null_resource.bravo.id    # charlie depends on bravo
  }
}

# Result: alpha → charlie → bravo → alpha (CIRCLE!)
```

### The Error You'll See
```bash
$ terraform plan
│ Error: Cycle: null_resource.alpha, null_resource.bravo, null_resource.charlie
```

**What This Means:**
- Terraform can't determine creation order
- DAGs (from Chapter 5.1) don't allow cycles
- The resources listed form a circular dependency

### Real-World Example
```bash
# Common scenario: Security groups referencing each other
resource "aws_security_group" "app" {
  name = "app-sg"
  
  ingress {
    from_port       = 3000
    to_port         = 3000
    protocol        = "tcp"
    security_groups = [aws_security_group.db.id]  # app needs db
  }
}

resource "aws_security_group" "db" {
  name = "db-sg"
  
  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.app.id]  # db needs app
  }
}

# Creates: app → db → app (CIRCULAR!)
```

### How to Fix Circular Dependencies

**Solution 1: Use a Shared Variable**
```bash
# Instead of resources depending on each other, use a shared trigger
variable "build_id" {
  default = null
  type    = string
}

resource "null_resource" "alpha" {
  triggers = {
    rebuild = var.build_id  # All use same variable
  }
}

resource "null_resource" "bravo" {
  triggers = {
    rebuild = var.build_id  # No circular dependencies
  }
}

resource "null_resource" "charlie" {
  triggers = {
    rebuild = var.build_id  # Clean and simple
  }
}
```

**Solution 2: Separate Security Group Rules**
```bash
# Create security groups first (no dependencies)
resource "aws_security_group" "app" {
  name = "app-sg"
  # No ingress rules here
}

resource "aws_security_group" "db" {
  name = "db-sg"
  # No ingress rules here
}

# Add rules separately (breaks the cycle)
resource "aws_security_group_rule" "app_to_db" {
  type                     = "egress"
  from_port                = 5432
  to_port                  = 5432
  protocol                 = "tcp"
  security_group_id        = aws_security_group.app.id
  source_security_group_id = aws_security_group.db.id
}

resource "aws_security_group_rule" "db_from_app" {
  type                     = "ingress"
  from_port                = 5432
  to_port                  = 5432
  protocol                 = "tcp"
  security_group_id        = aws_security_group.db.id
  source_security_group_id = aws_security_group.app.id
}
```

### Prevention Tips
- Keep dependencies simple and one-directional
- Use `terraform graph` to visualize relationships
- When you see cycles, look for shared values you can extract

## Cascading Changes

### What Are Cascading Changes?

Cascading changes happen when **one small change triggers many other changes** - like dominoes falling:

```bash
# You change this:
resource "tls_private_key" "ca_key" {
  algorithm = "ED25519"  # Changed from "ECDSA"
}

# But it affects everything that depends on it:
# → CA certificate gets recreated
# → All child certificates get recreated  
# → All services using those certificates restart
# → Load balancers update their SSL configs
```

### Real-World Example

**The Problem:**
```bash
# Original TLS setup
resource "tls_private_key" "ca_key" {
  algorithm = "ECDSA"  # Original algorithm
  ecdsa_curve = "P256"
}

resource "tls_self_signed_cert" "ca_cert" {
  private_key_pem = tls_private_key.ca_key.private_key_pem
  # ... other config
}

resource "tls_locally_signed_cert" "child_certificate" {
  for_each = toset(["example.com", "bravo.example.com", "charlie.example.com"])
  
  ca_private_key_pem = tls_private_key.ca_key.private_key_pem
  ca_cert_pem        = tls_self_signed_cert.ca_cert.cert_pem
  # ... other config
}
```

**What Happens When You Change the Algorithm:**
```bash
$ terraform plan

# tls_private_key.ca_key must be replaced
-/+ resource "tls_private_key" "ca_key" {
      ~ algorithm = "ECDSA" -> "ED25519" # forces replacement
    }

# tls_self_signed_cert.ca_cert must be replaced  
-/+ resource "tls_self_signed_cert" "ca_cert" {
      ~ ca_private_key_pem = (sensitive value) # forces replacement
    }

# tls_locally_signed_cert.child_certificate["example.com"] must be replaced
-/+ resource "tls_locally_signed_cert" "child_certificate" {
      ~ ca_cert_pem        = <<-EOT # forces replacement
      ~ ca_private_key_pem = (sensitive value) # forces replacement
    }

# ... same for bravo.example.com and charlie.example.com

Plan: 5 to add, 0 to change, 5 to destroy.
```

**One change = 5 resources replaced!**

### How to Handle Cascading Changes

**1. Always Review Plans Carefully**
```bash
# Look for these warning signs:
terraform plan
# → Pay attention to "forces replacement"
# → Count how many resources are affected
# → Understand why each change is happening
```

**2. Use `ignore_changes` to Prevent Unwanted Replacements**
```bash
resource "tls_private_key" "ca_key" {
  algorithm = "ECDSA"
  
  lifecycle {
    ignore_changes = [
      algorithm,  # Don't replace if algorithm changes
      ecdsa_curve # Don't replace if curve changes
    ]
  }
}
```

**3. Reduce Dependency Chains**
```bash
# Instead of this (tight coupling):
resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  subnet_id     = aws_subnet.web.id
  security_groups = [aws_security_group.web.id]
  key_name      = aws_key_pair.web.key_name
}

# Consider this (looser coupling):
resource "aws_instance" "web" {
  ami           = var.ami_id          # Use variables
  subnet_id     = var.subnet_id       # Instead of direct
  security_groups = var.security_group_ids  # Dependencies
  key_name      = var.key_name
}
```

### Prevention Tips

- **Use `terraform graph`** to visualize dependencies
- **Test changes in development** before production
- **Consider using `create_before_destroy`** for critical resources
- **Plan incrementally** - make small changes, not big ones

## Hidden Dependencies

### What Are Hidden Dependencies?

Hidden dependencies happen when **resources need each other but Terraform doesn't know it**:

```bash
# These resources depend on each other in real life:
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
}

resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id
  # NAT Gateway needs Internet Gateway to work
  # But Terraform doesn't see this connection!
}

# Result: NAT Gateway might be created before Internet Gateway
# → NAT Gateway creation fails
```

### Real-World Examples

**Problem 1: Network Dependencies**
```bash
# This can fail:
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id  # This creates explicit dependency
  }
}

resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id
  # Hidden dependency: needs Internet Gateway to be attached first!
}
```

**Problem 2: Service Dependencies**
```bash
# Microservices that need each other:
resource "aws_ecs_service" "api" {
  name = "api-service"
  # Starts immediately
}

resource "aws_ecs_service" "database" {
  name = "database-service"  
  # API service needs this but Terraform doesn't know
}

# Result: API service starts before database is ready
# → API service fails to connect
```

### How to Fix Hidden Dependencies

**Solution: Use `depends_on`**
```bash
# Fix network dependency:
resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id
  
  depends_on = [
    aws_internet_gateway.main  # Explicit dependency
  ]
}

# Fix service dependency:
resource "aws_ecs_service" "api" {
  name = "api-service"
  
  depends_on = [
    aws_ecs_service.database  # API waits for database
  ]
}
```

**Alternative: Create Explicit Attribute Dependencies**
```bash
# Instead of depends_on, use resource attributes:
resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id
  
  tags = {
    InternetGateway = aws_internet_gateway.main.id  # Creates dependency
  }
}
```

### When Hidden Dependencies Are OK

**Microservices with retry logic:**
```bash
# These can handle temporary failures:
resource "kubernetes_deployment" "frontend" {
  # Will retry connecting to backend
}

resource "kubernetes_deployment" "backend" {
  # Frontend can wait for this to be ready
}
```

**When NOT to worry:**
- Services have built-in retry mechanisms
- Temporary failures are acceptable
- Services can start in any order

### Prevention Tips

- **Use `terraform graph`** to visualize actual dependencies
- **Test your infrastructure** from scratch regularly
- **Add `depends_on`** when you see creation failures
- **Consider the real-world startup order** of your services

## Always Detected Changes

### What Are Always Detected Changes?

This is the **"eternal drift" problem** - Terraform keeps detecting changes even after you apply them:

```bash
# You run this cycle forever:
$ terraform plan
# Shows changes to make

$ terraform apply  
# Applies the changes

$ terraform plan
# Still shows the SAME changes!
# This repeats endlessly...
```

### Why This Happens

**The root cause:** Provider translation problems between Terraform and APIs:

```bash
# You write this:
resource "aws_instance" "example" {
  instance_type = "t3.micro"
  monitoring    = true
  cpu_credits   = 45
}

# API returns this:
{
  "instance_type": "t3.micro",
  "monitoring": "true",      # Boolean became string!
  "cpu_credits": 45.0        # Integer became float!
}

# Terraform sees differences:
# monitoring: true → "true" (change detected)
# cpu_credits: 45 → 45.0 (change detected)
```

### Common Translation Problems

**1. Data Type Conversions**
```bash
# Integer to Float
resource "example" "test" {
  count = 5          # You set: 5
}                    # API returns: 5.0
                     # Terraform sees: 5 → 5.0 (change!)

# Boolean to String  
resource "example" "test" {
  enabled = true     # You set: true
}                    # API returns: "true"
                     # Terraform sees: true → "true" (change!)
```

**2. List Ordering**
```bash
# You define:
resource "aws_security_group" "example" {
  ingress {
    cidr_blocks = ["10.0.1.0/24", "10.0.2.0/24"]
  }
}

# API returns (different order):
# cidr_blocks = ["10.0.2.0/24", "10.0.1.0/24"]
# Terraform sees this as a change!
```

**3. Case Sensitivity**
```bash
# You write:
resource "example" "test" {
  name = "MyResource"    # Mixed case
}

# API returns:
# name = "myresource"    # Lowercase
# Terraform detects: "MyResource" → "myresource" (change!)
```

**4. Empty Values**
```bash
# You don't set optional field:
resource "example" "test" {
  # description not specified
}

# API returns:
# description = ""       # Empty string
# Terraform sees: null → "" (change!)
```

### How to Fix Always Detected Changes

**1. Match Your Input to API Output**
```bash
# Instead of this:
resource "aws_security_group" "example" {
  ingress {
    cidr_blocks = ["10.0.1.0/24", "10.0.2.0/24"]  # Random order
  }
}

# Do this (match API order):
resource "aws_security_group" "example" {
  ingress {
    cidr_blocks = sort(["10.0.1.0/24", "10.0.2.0/24"])  # Sorted order
  }
}
```

**2. Use Correct Data Types**
```bash
# Instead of this:
resource "example" "test" {
  cpu_credits = 45        # Integer
  enabled     = true      # Boolean
}

# Do this (match API types):
resource "example" "test" {
  cpu_credits = "45"      # String if API returns string
  enabled     = "true"    # String if API returns string
}
```

**3. Use `ignore_changes` as Last Resort**
```bash
resource "example" "test" {
  problematic_field = "value"
  
  lifecycle {
    ignore_changes = [
      problematic_field  # Stop detecting changes on this field
    ]
  }
}
```

### Prevention and Reporting

**Test your resources:**
```bash
# Always test this cycle:
terraform plan   # Should show changes
terraform apply  # Apply changes  
terraform plan   # Should show "No changes"

# If step 3 shows changes, you have this problem
```

**Report provider bugs:**
- Check the provider's GitHub issues
- File a bug report if not already reported
- Include your configuration and the detected changes
- This helps improve the provider for everyone

## Calculated Values and Iterations

### What's the Problem?

**Terraform can't use "unknown" values in `count` and `for_each`:**

```bash
# This FAILS:
resource "aws_instance" "web" {
  count = length(aws_subnet.private.*.id)  # ❌ Unknown at plan time
}

resource "aws_security_group_rule" "rules" {
  for_each = toset(aws_instance.web.*.id)  # ❌ Unknown at plan time
}
```

### Why This Happens

**Terraform needs to build the resource graph BEFORE creating anything:**

```bash
# Planning Phase (what Terraform knows):
# ✅ Variables and locals
# ✅ Data sources  
# ✅ Hard-coded values
# ❌ Resource attributes (don't exist yet!)

# Apply Phase (too late for count/for_each):
# ✅ All resource attributes now available
# ❌ But graph is already built
```

### Real-World Example That Fails

```bash
variable "domain" {
  description = "The base domain to use for DNS records."
  type        = string
}

locals {
  # ❌ This uses a resource attribute!
  use_eip = endswith("example.com", aws_route53_record.example.name)
}

resource "aws_instance" "example" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t3.micro"
}

resource "aws_eip" "example" {
  count  = local.use_eip ? 1 : 0  # ❌ FAILS - uses resource attribute
  domain = "vpc"
}

resource "aws_route53_record" "example" {
  zone_id = data.aws_route53_zone.example.id
  name    = "instance.${data.aws_route53_zone.example.id}"
  type    = "A"
  records = [aws_instance.example.public_ip]
}
```

**Error you'll see:**
```bash
$ terraform plan
│ Error: Invalid count argument
│ The "count" value depends on resource attributes that cannot be determined until apply
```

### How to Fix Calculated Value Problems

**Solution: Use input variables instead of resource attributes:**

```bash
# ✅ FIXED VERSION:
variable "domain" {
  description = "The base domain to use for DNS records."
  type        = string
}

locals {
  # ✅ Uses variable instead of resource attribute
  use_eip = endswith("example.com", var.domain)
}

resource "aws_instance" "example" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t3.micro"
}

resource "aws_eip" "example" {
  count  = local.use_eip ? 1 : 0  # ✅ WORKS - uses variable
  domain = "vpc"
}

resource "aws_route53_record" "example" {
  zone_id = data.aws_route53_zone.example.id
  name    = "instance.${data.aws_route53_zone.example.id}"
  type    = "A"
  records = [aws_instance.example.public_ip]
}
```

### Alternative Solutions

**1. Use known values only:**
```bash
# Instead of this (unknown):
resource "aws_instance" "web" {
  count = length(aws_subnet.private.*.id)  # ❌ Unknown
}

# Do this (known):
resource "aws_instance" "web" {
  count = var.instance_count  # ✅ Known variable
}
```

**2. Use data sources:**
```bash
# Get existing resources instead of creating them:
data "aws_subnets" "private" {
  filter {
    name   = "vpc-id"
    values = [var.vpc_id]
  }
}

resource "aws_instance" "web" {
  count = length(data.aws_subnets.private.ids)  # ✅ Known at plan time
}
```

**3. Split into multiple applies (NOT recommended):**
```bash
# Apply 1: Create base resources
resource "aws_instance" "web" {
  count = 3
}

# Apply 2: Use resource targeting (avoid this approach)
# terraform apply -target=aws_security_group_rule.rules
```

### Prevention Tips

- **Use variables and data sources** for count/for_each
- **Avoid resource attributes** in count/for_each calculations  
- **Test your modules** with fresh state files
- **Consider splitting complex logic** into separate configurations

## Failed State Updates

### What Are Failed State Updates?

This is when **Terraform makes changes to infrastructure but fails to record them in state**:

```bash
# What should happen:
$ terraform apply
# 1. Creates AWS instance
# 2. Updates state file with instance ID
# 3. Shows "Apply complete!"

# What actually happens (rare bug):
$ terraform apply  
# 1. Creates AWS instance ✅
# 2. State update fails ❌ (system crash, network error, etc.)
# 3. State file is not updated

# Result: Infrastructure exists but Terraform doesn't know about it
```

### Why This Happens

**System-level failures during state updates:**
- Terraform process crashes mid-apply
- Network connection lost to remote state backend
- State backend (S3, Consul, etc.) returns errors
- Disk full when writing local state
- Permission issues with state file

### Types of Failed State Updates

**1. Updates and Deletions (easier to fix):**
```bash
# Terraform knows the resource exists (has ID in state)
# But failed to record the changes made to it
resource "aws_instance" "web" {
  instance_type = "t3.large"  # Changed from t3.micro
}

# After failed state update:
# - AWS instance is actually t3.large
# - State still shows t3.micro
# - Next plan shows the same change again
```

**2. New Resource Creation (harder to fix):**
```bash
# Terraform creates new resource but fails to save ID
resource "aws_instance" "new" {
  ami           = "ami-12345"
  instance_type = "t3.micro"
}

# After failed state update:
# - AWS instance exists with ID i-abcd1234
# - State file has no record of this resource
# - Terraform thinks resource doesn't exist
```

### How to Fix Failed State Updates

**For Updates/Deletions (has existing state):**
```bash
# Use refresh-only apply to sync state with reality
$ terraform apply -refresh-only

# This will:
# 1. Check actual infrastructure state
# 2. Update state file to match reality
# 3. Not make any changes to infrastructure

# Then verify everything is aligned:
$ terraform plan
# Should show "No changes" if successful
```

**For New Resources (no existing state):**

**Option 1: Import the resource**
```bash
# Find the resource ID from cloud console
# Import it into Terraform state
$ terraform import aws_instance.new i-abcd1234

# Then verify:
$ terraform plan
# Should show "No changes"
```

**Option 2: Delete and recreate**
```bash
# Manually delete the orphaned resource
# From AWS console or CLI
$ aws ec2 terminate-instances --instance-ids i-abcd1234

# Then run refresh and apply
$ terraform apply -refresh-only
$ terraform apply
# Creates the resource properly this time
```

### Prevention Tips

- **Use remote state backends** with high availability (S3, Terraform Cloud)
- **Enable state locking** to prevent concurrent modifications
- **Monitor apply operations** - don't walk away during long applies
- **Use state backups** - most backends create automatic backups
- **Test state backend connectivity** before critical applies

### Recovery Best Practices

```bash
# Always start with refresh to understand current state
$ terraform apply -refresh-only

# Check what Terraform thinks vs reality
$ terraform plan

# For complex scenarios, use state commands
$ terraform state list
$ terraform state show aws_instance.example

# Import missing resources one by one
$ terraform import <resource_type>.<name> <resource_id>
```

## Summary

This chapter covered the most common Terraform pitfalls:

✅ **Circular Dependencies** - Break cycles with shared variables or separate resources  
✅ **Cascading Changes** - Use `ignore_changes` and test changes carefully  
✅ **Hidden Dependencies** - Add explicit `depends_on` when needed  
✅ **Always Detected Changes** - Match your input to API output formats  
✅ **Calculated Values** - Use variables instead of resource attributes in count/for_each  
✅ **Failed State Updates** - Use refresh-only applies and import commands to recover  
✅ **Circular Dependencies** - Break cycles with shared variables or separate resources  
✅ **Cascading Changes** - Use `ignore_changes` and test changes carefully  

**Next:** Chapter 6 covers state management in detail, helping you prevent many of these issues.